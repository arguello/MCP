#!/usr/bin/python -u
#
#  sark
#
#   Checkes QueuItems to see if their resources are aviable, if they are, creates a buildjob and assigns resources
#   runs the Jobs through, when job complets calls signalcomplete on the attached Commit or Promotion

import os

os.environ.setdefault( "DJANGO_SETTINGS_MODULE", "mcp.settings" )

import sys
import logging
import json
from logging.handlers import SysLogHandler
from datetime import datetime, timedelta

from django.utils.timezone import utc
from mcp.Processor.models import QueueItem, BuildJob
from mcp.Resources.models import Resource

CLEANUP_DELAY = 2
PID_FILE = '/var/run/sark.pid'

logging.basicConfig()
logger = logging.getLogger()
handler = SysLogHandler( address='/dev/log', facility=SysLogHandler.LOG_DAEMON )
handler.setFormatter( logging.Formatter( fmt='sark[%(process)d]: %(message)s' ) )
logger.addHandler( handler )
logging.info( 'Starting...' )
if '-v' in sys.argv:
  logger.setLevel( logging.DEBUG )

else:
  logger.setLevel( logging.INFO )

if os.path.exists( PID_FILE ):
  logging.error( 'pid file exists, bailing...' )
  sys.exit( 0 )

tmp = open( PID_FILE, 'w' )
tmp.write( '%s\n' % os.getpid() )
tmp.close()

# Iterate over the Queued Items
for item in QueueItem.objects.all().order_by( '-priority' ): # start with the biggest number first
  try:
    # Check to see if resources are aviable
    status = item.checkResources()
    if status:
      logging.info( 'Queue Item "%s" waiting for "%s"' % ( item, status ))
      item.resource_status = json.dumps( status )
      item.save()
      continue
  except Exception as e:
    logging.exception( 'Exception "%s" checking resources for item "%s", skiping...' % ( e, item.pk ) )
    item.resource_status = json.dumps( { 'error': 'Exception: "%s"' % e } )
    item.save()
    continue

  job = None
  try:
    # Build a job
    job = BuildJob()
    job.manual = item.manual
    job.build = item.build
    job.project = item.project
    job.branch = item.branch
    job.target = item.target
    job.requires = item.requires
    job.commit = item.commit
    job.promotion = item.promotion
    job.save()

    # allocate the Resources
    resources = item.allocateResources( job )
    logging.info( 'Starting Queue Item "%s" with Resources "%s" as job "%s"' % ( item, resources, job.id ) )
    job._resources = json.dumps( resources )
    job.save()

  except Exception as e:
    logging.exception( 'Exception "%s" creating job for queue item "%s", skiping...' % ( e, item.pk ) )
    if job and job.pk:
      job.delete()

    item.resource_status = json.dumps( { 'error': 'Exception: "%s"' % e } )
    item.save()
    continue

  # remove the queue Item
  item.delete()

# Iterate over the build new jobs
for job in BuildJob.objects.filter( built_at__isnull=True ):
  ready = True
  resource_map = job.resources
  for name in resource_map:
    for index in range( 0, len( resource_map[ name ] ) ):
      if resource_map[ name ][ index ][ 'status' ] not in ( 'Allocated', 'Building' ):
        continue # don't want to overwrite any new status that might of been put in by something else, hopfully that something else waited till it was built, b/c we are going to assume it is, really should keep track of feedback status and building status seperately

      tmp = Resource.built( resource_map[ name ][ index ][ 'config' ] )
      ready &= tmp
      job.updateResourceState( name, index, 'Built' if tmp else 'Building' )

  # all done, set to built
  if ready:
    logging.info( 'Setting job "%s" to Built.' % job.id )
    job.built_at = datetime.utcnow().replace( tzinfo=utc )
    job.save()

# the Job will flag it's self as Ran

# Iterate over the Ran jobs, and for now fake report them
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=False, reported_at__isnull=True ):
  if job.commit is not None:
    job.commit.signalComplete( job.target, job.build.name, job.resources )

  elif job.promotion is not None:
    job.promotion.signalComplete( job.build )

  else:
    logging.warning( 'Job has nothing to report to, hopfully that was intentional' )

  logging.info( 'Setting job "%s" to Reported.' % job.id )
  job.reported_at = datetime.utcnow().replace( tzinfo=utc )
  job.save()

# iterate over the Reported jobs that are not manual, and release the resources
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=False, reported_at__isnull=False, released_at__isnull=True, manual=False ):
  resource_map = job.resources
  for name in resource_map:
    for index in range( 0, len( resource_map[ name ] ) ):
      if resource_map[ name ][ index ][ 'status' ] not in ( 'Releasing', 'Released' ):
        logging.info( 'Releasing resource "%s" "%s" of job "%s".' % ( name, index, job.id ) )
        if Resource.release( resource_map[ name ][ index ][ 'config' ]  ) is None:
          job.updateResourceState( name, index, 'Released' )
        else:
          job.updateResourceState( name, index, 'Releasing' )

# iterate over the Reported jobs and look to see if the resources are all released
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=False, reported_at__isnull=False, released_at__isnull=True ):
  resource_map = job.resources
  for name in resource_map:
    for index in range( 0, len( resource_map[ name ] ) ):
      if resource_map[ name ][ index ][ 'status' ] == 'Releasing':
        if Resource.released( resource_map[ name ][ index ][ 'config' ] ):
          job.updateResourceState( name, index, 'Released' )

  resource_map = job.resources
  ready = True
  for name in resource_map:
    for index in range( 0, len( resource_map[ name ] ) ):
      ready &= resource_map[ name ][ index ][ 'status' ] == 'Released'

  # resources all released, set job to released
  if ready:
    logging.info( 'Setting job "%s" to Released.' % job.id )
    job.released_at = datetime.utcnow().replace( tzinfo=utc )
    job.save()

# Iterate over released jobs that are at least CLEANUP_DELAY hours old and delete them
for job in BuildJob.objects.filter( released_at__lt=( datetime.utcnow().replace( tzinfo=utc ) - timedelta( hours=CLEANUP_DELAY ) ) ):
  logging.info( 'Cleaning up job "%s".' % job.id )
  job.delete()

os.unlink( PID_FILE )
logging.info( 'Done!' )
logging.shutdown()
sys.exit( 0 )
